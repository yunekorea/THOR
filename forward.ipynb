{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Testing 12 Attention Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), './src'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import pickle    \n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from transformers import BertForNextSentencePrediction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from liberate.fhe.bootstrapping import ckks_bootstrapping as bs\n",
    "\n",
    "import thor\n",
    "from thor import CkksEngine, ThorDataEncryptor, ThorLinearEvaluator\n",
    "from thor.bert import ThorBert, ThorBertFF, ThorBertPooler, ThorBertClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Initiate CKKS Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [0]\n",
    "\n",
    "with torch.cuda.device(devices[0]):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_allocated(devices[0]) /1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"logN\":16, \"scale_bits\": 41, \"num_special_primes\": 4, \"devices\": devices, \"quantum\":\"pre_quantum\"}\n",
    "engine = CkksEngine(params)\n",
    "print(\"Memory allocated: \", torch.cuda.memory_allocated(devices[0]) /1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Pre-Generated Keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotk_dict_keys = [\n",
    "    -32768, -16384, -1024, -512, -32, -16,\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
    "    32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384,\n",
    "    416, 448, 480, 512, 1024, 2048, 3072, 4096, 5120, 6144,\n",
    "    7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336,\n",
    "    15360, 16384\n",
    "]                    \n",
    "\n",
    "deltas = [    \n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
    "    10, 11, 12, 16, 2048, 4096, 6144, 8192, 10240,\n",
    "    12288, 14336, 18432, 20480, 22528, 24576, 26624, 28672, 30720,\n",
    "    256, 2288, 4320, 6352, 8384, 10416, 12448, 14480, 16512,\n",
    "    18544, 20576, 22608, 24640, 26672, 28704, 30736,\n",
    "    512, 768, 1280, 2544, 2800, 3312, 4576, 4832, 5344,\n",
    "    6608, 6864, 8640, 8896, 10672,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = engine.load(\"./keys/keys0/sk\")\n",
    "pk = engine.load(f\"./keys/keys0/pk\")\n",
    "engine.add_pk(pk)\n",
    "evk = engine.load(f\"./keys/keys0/evk\")\n",
    "engine.add_evk(evk)\n",
    "gk = engine.load(f\"./keys/keys0/gk\")\n",
    "engine.add_gk(gk)\n",
    "conjk = engine.load(f\"./keys/keys0/conjk\")\n",
    "engine.add_conj_key(conjk)\n",
    "rotk_dict = {}\n",
    "for key in rotk_dict_keys:\n",
    "    rotk_dict[key] = engine.load(f\"./keys/keys0/rotk_dict/{key}\")\n",
    "bs.create_cts_stc_const(engine)\n",
    "engine.add_bs_key(rotk_dict)\n",
    "engine.add_rot_keys_from_sk(deltas, sk)\n",
    "print(\"Memory allocated: \", torch.cuda.memory_allocated(devices[0]) /1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Load and Encrypt Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Datatset Type and Target Data Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'mrpc'\n",
    "target_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate DataEncryptor and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f'./datasets/{dataset_type}'\n",
    "\n",
    "data_encryptor = ThorDataEncryptor(dataset_type, dataset,\n",
    "                                   embedding_model=BertForNextSentencePrediction.from_pretrained('bert-base-uncased').bert.embeddings, \n",
    "                                   ckks_engine=engine, test=False)\n",
    "data_loader = data_encryptor.eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encrypt Data as \"x\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_attention_mask(engine, attention_mask:np.ndarray, level:int=15) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return an array of size (8,) which contains 8 plaintexts. \n",
    "    \"\"\"\n",
    "    if attention_mask.shape != (128,):\n",
    "        raise ValueError(\"Shape of attention mask should be (128,)\")\n",
    "    n_tokens = np.count_nonzero(attention_mask)\n",
    "    attention_mask = np.full((8,), None, dtype=object)\n",
    "    for i in range(8):\n",
    "        msg = np.zeros((2**15,), dtype=float)\n",
    "        for j in range(16):\n",
    "            temp = j *(2**11)\n",
    "            diag_index = i * 16 + j\n",
    "            for t in range(128):\n",
    "                col_index = (diag_index + t) % 128\n",
    "                is_token = 1 if col_index < n_tokens else 0\n",
    "                for head in range(12):\n",
    "                    msg[temp + t*16 + head] = is_token\n",
    "        attention_mask[i] = engine.encode(msg, level)\n",
    "    return attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for batch in data_loader:\n",
    "    if idx < target_idx:\n",
    "        idx += 1\n",
    "        continue\n",
    "    if idx == target_idx:\n",
    "        data= {k: v for k, v in batch.items() if k in ['input_ids', 'token_type_ids']}\n",
    "        embedding = data_encryptor.embed_data(data)\n",
    "        x = data_encryptor.encrypt_embedding(embedding, pk, level = 20)\n",
    "        attention_mask = batch['attention_mask']\n",
    "        thor_attention_mask = data_encryptor.encode_attention_mask(attention_mask.cpu().numpy().squeeze().T, level=15)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Load and Run plain(non HE) Model for Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Run Plain Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plain  = thor.utils.load_model(dataset_type, f'./finetuned_models/{dataset_type}/model.safetensors')\n",
    "model_plain.eval()\n",
    "device = torch.device(\"cpu\")\n",
    "model_plain.to(device)\n",
    "idx = 0\n",
    "for batch in data_loader:\n",
    "    print(idx, target_idx)\n",
    "    if idx < target_idx:\n",
    "        idx += 1\n",
    "        continue\n",
    "    elif idx == target_idx:\n",
    "        batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model_plain(**batch)\n",
    "        break\n",
    "\n",
    "def get_nonlinear_in_out(hidden_states, layer_idx):\n",
    "    with torch.no_grad():\n",
    "        bert_layer_m = model_plain.bert.encoder.layer[layer_idx] \n",
    "        attention_m = bert_layer_m.attention.self\n",
    "        bert_output_m = model_plain.bert.encoder.layer[layer_idx].attention.output\n",
    "\n",
    "        q = attention_m.transpose_for_scores(attention_m.query(hidden_states))\n",
    "        k = attention_m.transpose_for_scores(attention_m.key(hidden_states))\n",
    "        v = attention_m.transpose_for_scores(attention_m.value(hidden_states))\n",
    "        attention_scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(attention_m.attention_head_size)\n",
    "        extended_att_mask = model_plain.get_extended_attention_mask(\n",
    "                        attention_mask, 768\n",
    "                    ).to(device)\n",
    "        sfmtx_in = attention_scores+extended_att_mask\n",
    "        att_probs_m = torch.nn.functional.softmax(sfmtx_in, dim=-1)\n",
    "        sfmtx_out = att_probs_m\n",
    "        att_context_m = torch.matmul(att_probs_m, v)\n",
    "        context_layer = att_context_m.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (attention_m.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "        dense_output_m = bert_output_m.dense(context_layer)\n",
    "        ln1_in = dense_output_m + hidden_states\n",
    "        ln1_out = bert_output_m.LayerNorm(ln1_in)\n",
    "        gelu_in = bert_layer_m.intermediate.dense(ln1_out)\n",
    "        gelu_out = bert_layer_m.intermediate.intermediate_act_fn(gelu_in)\n",
    "        dense2_out = bert_layer_m.output.dense(gelu_out)\n",
    "        ln2_in = dense2_out + ln1_out\n",
    "        ln2_out = bert_layer_m.output.LayerNorm(ln2_in)\n",
    "        pooler_m = model_plain.bert.pooler\n",
    "        pooler_dense_output = pooler_m.dense(ln2_out[:, 0])\n",
    "        print(ln2_out[:, 0].shape)\n",
    "        pooler_output = pooler_m.activation(pooler_dense_output)\n",
    "\n",
    "    return (\n",
    "        hidden_states.cpu().numpy().squeeze(),\n",
    "        q.cpu().numpy().squeeze(),\n",
    "        sfmtx_in.cpu().numpy().squeeze(),\n",
    "        sfmtx_out.cpu().numpy().squeeze(),\n",
    "        att_context_m.cpu().numpy().squeeze(),\n",
    "        ln1_in.cpu().numpy().squeeze(),\n",
    "        ln1_out.cpu().numpy().squeeze(),\n",
    "        gelu_in.cpu().numpy().squeeze(),\n",
    "        gelu_out.cpu().numpy().squeeze(),\n",
    "        dense2_out.cpu().numpy().squeeze(),\n",
    "        ln2_in.cpu().numpy().squeeze(),\n",
    "        ln2_out.cpu().numpy().squeeze(),\n",
    "        pooler_dense_output.cpu().numpy().squeeze(),\n",
    "        pooler_output.cpu().numpy().squeeze()\n",
    "        )\n",
    "    \n",
    "hidden_states = []\n",
    "qs= []\n",
    "ks = []\n",
    "sftmx_ins = []\n",
    "sftmx_outs = []\n",
    "att_contexts = []\n",
    "ln1_ins = []\n",
    "ln1_outs = []\n",
    "gelu_ins = []\n",
    "gelu_outs = []\n",
    "dense2_outs = []\n",
    "ln2_ins = []\n",
    "ln2_outs = []\n",
    "for layer in range(12):\n",
    "    hidden_state, q, sftmx_in, sftmx_out, att_context, ln1_in, ln1_out, gelu_in, gelu_out, dense2_out, ln2_in, ln2_out, pooler_dense_out, pooler_out = get_nonlinear_in_out(outputs.hidden_states[layer], layer)\n",
    "    hidden_states.append(hidden_state)\n",
    "    qs.append(q)\n",
    "    sftmx_ins.append(sftmx_in)\n",
    "    sftmx_outs.append(sftmx_out)\n",
    "    att_contexts.append(att_context)\n",
    "    ln1_ins.append(ln1_in)\n",
    "    ln1_outs.append(ln1_out)\n",
    "    gelu_ins.append(gelu_in)\n",
    "    gelu_outs.append(gelu_out)\n",
    "    dense2_outs.append(dense2_out)\n",
    "    ln2_ins.append(ln2_in)\n",
    "    ln2_outs.append(ln2_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Load HE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"./encoded_models_new/{dataset_type}/att.pkl\", 'rb') as f:\n",
    "    weights_pt = pickle.load(f)\n",
    "\n",
    "with open(f\"./encoded_models_new/{dataset_type}/ff.pkl\", 'rb') as f:\n",
    "    ff_weights = pickle.load(f)\n",
    "    \n",
    "with open(f\"./encoded_models_new/{dataset_type}/pooler.pkl\", 'rb') as f:\n",
    "    pooler_weights = pickle.load(f)\n",
    "\n",
    "with open(f\"./encoded_models_new/{dataset_type}/cls.pkl\", 'rb') as f:\n",
    "    classifier_weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate HE Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator = ThorLinearEvaluator(engine) #LinearEvaluator does operations such as HE-matmul.\n",
    "\n",
    "thor_bert = ThorBert(evaluator, weights_pt)\n",
    "thor_ffs = []\n",
    "\n",
    "for i in range(12):\n",
    "    thor_ffs.append(ThorBertFF(evaluator, ff_weights, i))\n",
    "thor_bert.ffs = thor_ffs\n",
    "thor_bert.pooler = ThorBertPooler(evaluator, pooler_weights)\n",
    "thor_bert.classifier = ThorBertClassifier(evaluator, classifier_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Forward Layer Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def forward_layer(x):\n",
    "    global engine, evaluator, thor_attention,thor_ff, layer_idx, thor_attention_mask, time1, time2, time3, time4, time5, time6, time7, time8, time9, time10, time11, time12, time13, time14\n",
    "    \n",
    "    thor_attention.to(devices)\n",
    "    thor_ff.to(devices)\n",
    "    print(\"layer_idx:\", layer_idx)\n",
    "    \n",
    "    if x.shape == (8,):\n",
    "        x_cplx = np.full((4,), None, dtype=object)\n",
    "        for i in range(4):\n",
    "            x_cplx[i] = engine.cc_add(x[i], engine.imult(x[i+4]))\n",
    "        if layer_idx != 0:\n",
    "            for i in range(4):\n",
    "                x_cplx[i] = engine.cc_add(x_cplx[i], engine.rotate_left(x_cplx[i], -6))\n",
    "    elif x.shape == (4,):\n",
    "        x_cplx = x\n",
    "        x = np.full((8,), None, dtype=object)\n",
    "        for i in range(4):\n",
    "            conj = engine.conjugate(x_cplx[i])\n",
    "            x[i] =  engine.mult_scalar(engine.cc_add(x_cplx[i], conj), 1/2)\n",
    "            x[i+4] =  engine.mult_scalar(engine.imult(engine.cc_sub(conj, x_cplx[i])), 1/2)\n",
    "            x_cplx[i] = engine.level_up(x_cplx[i], 21)\n",
    "    \n",
    "    # WF 1. Attention layer\n",
    "    x_cplx_rots = evaluator.make_rotated_copies(x_cplx)\n",
    "    q_wo_rescale = thor_attention.query(x_cplx_rots)\n",
    "    k = thor_attention.key(x_cplx_rots)\n",
    "    v = thor_attention.value(x_cplx_rots)\n",
    "\n",
    "    l_k = evaluator.transpose_upper_to_lower(k)\n",
    "    l_k_cplx = np.full((4,), None, dtype=object)\n",
    "    for i in range(4):\n",
    "        l_k_cplx[i] = engine.cc_add(engine.level_up(l_k[i], l_k[i].level_calc+1), engine.imult(evaluator.rotate_internal(l_k[i], 64, mode='att')))\n",
    "        l_k_cplx[i] = engine.rescale(l_k_cplx[i])\n",
    "    \n",
    "    # WF 2. Attention score\n",
    "    q = np.full_like(q_wo_rescale, None, dtype=object)\n",
    "    for i in range(4):\n",
    "        q[i] = engine.rescale(q_wo_rescale[i])\n",
    "    q_copies = evaluator.make_copies(q)\n",
    "    sftmx_scale = 1\n",
    "    sftmx_in = thor_attention.calculate_attention_score(l_k_cplx, q_copies, bootstrap=False, scale=sftmx_scale, rescale=False)\n",
    "\n",
    "    for i in range(4):\n",
    "        temp = engine.cc_add(sftmx_in[i], engine.imult(sftmx_in[i+4]))\n",
    "        # Bootstrap #1\n",
    "        temp = engine.bootstrap(temp)\n",
    "        conj = engine.conjugate(temp)\n",
    "        sftmx_in[i] = engine.cc_add(temp, conj)\n",
    "        sftmx_in[i+4] = engine.imult(engine.cc_sub(conj, temp))\n",
    "    \n",
    "    # WF 3. Soft weights(Softmax)\n",
    "    sftmx_out = thor_attention.softmax(x=sftmx_in, attention_mask=thor_attention_mask, rescale=False, debug=False, sk=None)\n",
    "\n",
    "    v_cplx = np.full((2,), None, dtype=object)\n",
    "    for i in range(2):\n",
    "        v_cplx[i] = engine.cc_add(v[i], engine.imult(v[i+2]))\n",
    "    if sftmx_out[0].level_calc < v_cplx[0].level_calc:\n",
    "        for j in range(128):\n",
    "            sftmx_out[j] = engine.level_up(sftmx_out[j], v[0].level_calc)\n",
    "    elif sftmx_out[0].level_calc > v_cplx[0].level_calc:\n",
    "        for j in range(2):\n",
    "            v_cplx[j] = engine.level_up(v_cplx[j], sftmx_out[0].level_calc)\n",
    "    for i in range(2):\n",
    "        v_cplx[i] = engine.rescale(v_cplx[i])\n",
    "    sftmx_out_rescale = np.full((128,), None, dtype=object)\n",
    "    for j in range(128):\n",
    "        sftmx_out_rescale[j] = engine.rescale(sftmx_out[j])\n",
    "    # WF 4. Attention head & multi-head attention\n",
    "    att_context = thor_attention.calculate_attention_context(v_cplx, sftmx_out_rescale, rescale=False)\n",
    "\n",
    "    # Bootstrap #2\n",
    "    for i in range(2):\n",
    "        att_context[i] = engine.bootstrap(att_context[i])\n",
    "\n",
    "    att_context_rots = thor_attention.evaluator.make_rotated_copies(att_context)\n",
    "    dense_output = thor_attention.dense(att_context_rots)\n",
    "    x_out_sum = np.full((8,), None, dtype=object)\n",
    "    mask = np.array(([1]*6+[0]*10)*2**11)\n",
    "    for i in range(4):\n",
    "        x_out_sum[i] = engine.add(x[i], dense_output[i])\n",
    "        x_out_sum[i+4] = engine.add(x[i+4], dense_output[i+4])\n",
    "    ln1_in = x_out_sum\n",
    "\n",
    "    # WF 5. LayerNorm1\n",
    "    ln1_out = thor_attention.layernorm(x=ln1_in, sk=None)\n",
    "    l = np.full((64,), None,dtype=object)\n",
    "    mask = np.full((engine.num_slots,), 1, dtype=int)\n",
    "    mask[np.arange(engine.num_slots) % (16) >= 6] = 0\n",
    "    for i in range(4):\n",
    "        temp = engine.cc_add(ln1_out[i], engine.imult(ln1_out[i+4]))\n",
    "        temp = engine.mc_mult(mask, temp)\n",
    "        l[16*i] = engine.cc_add(temp, engine.rotate_left(temp, -8))\n",
    "        for j in range(1, 16):\n",
    "            index = 16*i+j\n",
    "            l[index] = engine.rotate_left(l[index-1], 2**11)\n",
    "\n",
    "    # WF 6. FC1(Fully Connected layer; Feed-Forward Network Part 1)\n",
    "    gelu_in_wo_bs = thor_ff.dense1(l)\n",
    "\n",
    "    for i in range(8):\n",
    "        temp = engine.cc_add(gelu_in_wo_bs[0,i], engine.imult(gelu_in_wo_bs[1,i]))\n",
    "        temp = engine.mult_scalar(temp, 1/2)\n",
    "        #Bootstrap #3\n",
    "        temp = engine.bootstrap(temp)\n",
    "        conj = engine.conjugate(temp)\n",
    "        gelu_in_wo_bs[0,i] = engine.cc_add(temp, conj)\n",
    "        gelu_in_wo_bs[1,i] = engine.imult(engine.cc_sub(conj, temp))\n",
    "\n",
    "    # WF 7. GELU(Activation Function)\n",
    "    gelu_out = thor_ff.gelu(x=gelu_in_wo_bs)\n",
    "    # WF 8. FC2(Feed-Forward Network Part 2) \n",
    "    dense2_out = thor_ff.dense2(gelu_out)\n",
    "    ln2_in = np.full((8,), None, dtype=object)\n",
    "    for i in range(8):\n",
    "        ln2_in[i] = engine.add(ln1_out[i], dense2_out[i])\n",
    "    for i in range(4):\n",
    "        temp = engine.cc_add(ln2_in[i], engine.imult(ln2_in[i+4]))\n",
    "        # Bootstrap #4\n",
    "        temp = engine.bootstrap(temp)\n",
    "        conj = engine.conjugate(temp)\n",
    "        ln2_in[i] = engine.cc_add(temp, conj)\n",
    "        ln2_in[i+4] = engine.imult(engine.cc_sub(conj, temp)) \n",
    "\n",
    "    # WF 9. LayerNorm2\n",
    "    if layer_idx == 9 or layer_idx == 10:\n",
    "        ln2_out = thor_ff.layernorm(x=ln2_in, sk=None)\n",
    "    else:\n",
    "        ln2_out = thor_ff.layernorm(x=ln2_in, sk=None)\n",
    "\n",
    "    if ln2_out[0].level >8:\n",
    "        for i in range(8):\n",
    "            ln2_out[i] = engine.level_up(ln2_out[i], 21)\n",
    "        \n",
    "    thor_attention.cpu()\n",
    "    thor_ff.cpu()\n",
    "    return ln2_out, (x, q_wo_rescale, sftmx_in, sftmx_out, att_context, ln1_in, ln1_out, gelu_in_wo_bs, gelu_out, dense2_out, ln2_in, ln2_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Forward Attention Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Run and Plot Layer 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for Plotting and Comparison with Plain Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_list = []\n",
    "h_indices = [np.where(np.arange(0, 2**11) % 16 == i) for i in range(12)]\n",
    "\n",
    "def plot_variables(variables, i=0, j=0, h=0):\n",
    "    global layer_idx, sk, h_indices, engine, dd\n",
    "    variable_names = ['x', 'q', 'sftmx_in', 'sftmx_out', 'att_context', 'ln1_in', 'ln1_out', 'gelu_in_wo_bs', 'gelu_out', 'dense2_out', 'ln2_in', 'ln2_out']\n",
    "    global_vars = [hidden_states, qs, sftmx_ins,  sftmx_outs, att_contexts, ln1_ins, ln1_outs, gelu_ins, gelu_outs, dense2_outs, ln2_ins, ln2_outs]\n",
    "\n",
    "    fig, axs = plt.subplots(4, 3, figsize=(15, 15))\n",
    "    fig.suptitle(f'Variables Plot (Layer {layer_idx+1})', fontsize=16)\n",
    "\n",
    "    for index, (var, name, global_var) in enumerate(zip(variables, variable_names, global_vars)):\n",
    "        row = index // 3\n",
    "        col = index % 3\n",
    "        \n",
    "        if isinstance(var, np.ndarray) and var.ndim > 1:\n",
    "            var = var[0]\n",
    "        \n",
    "        if len(var) <= i:\n",
    "            print(f'{name} is not available: shape is {len(var)}')\n",
    "            continue\n",
    "        \n",
    "        current_var = engine.decrode(var[i], sk, is_real=True)[2**11*j:2**11*(j+1)][h_indices[h]]\n",
    "        global_var = global_var[layer_idx]\n",
    "\n",
    "        if global_var.ndim == 3:\n",
    "            global_var = global_var[h].T\n",
    "        elif name in ['gelu_in', 'gelu_out', 'gelu_in_wo_bs']:\n",
    "            global_var = np.vsplit(global_var.T, 24)[0]\n",
    "        else:\n",
    "            global_var = np.vsplit(global_var.T, 6)[h]\n",
    "        \n",
    "        global_var_layer = thor.utils.matrix.ld(global_var, i*16+j)\n",
    "\n",
    "        if name == 'sftmx_in':\n",
    "            global_var_layer = global_var_layer[:40]\n",
    "            current_var = current_var[:40]\n",
    "\n",
    "            if layer_idx != 2:\n",
    "                current_var = current_var * 32\n",
    "            else:\n",
    "                current_var = current_var * 64\n",
    "        elif name == 'gelu_in_wo_bs':\n",
    "            current_var = current_var * 64\n",
    "        elif name == \"ln2_in\" :\n",
    "            current_var = current_var/2\n",
    "            \n",
    "        axs[row, col].plot(current_var, label=f'HE {name}')\n",
    "        axs[row, col].plot(global_var_layer, label=f'Plain {name}', linestyle='--')\n",
    "        axs[row, col].set_title(name)\n",
    "        axs[row, col].grid(True)\n",
    "        axs[row, col].legend()\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Index', ylabel='Decoded Value')\n",
    "\n",
    "    axs[-1, -1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 0\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x1, variables =  forward_layer(x)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Run and Plot Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 1\n",
    "thor_attention = thor_bert.attentions[layer_idx]    \n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x2 , variables2 = forward_layer(x1)\n",
    "variables_list.append(variables2)\n",
    "plot_variables(variables2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Run and Plot Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 2\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x3, variables3 = forward_layer(x2)\n",
    "variables_list.append(variables3)\n",
    "plot_variables(variables3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Run and Plot Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 3\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x4, variables = forward_layer(x3)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. Run and Plot Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 4\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x5 , variables = forward_layer(x4)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. Run and Plot Layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 5\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x6 , variables = forward_layer(x5)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-7. Run and Plot Layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 6\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x7, variables = forward_layer(x6)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-8. Run and Plot Layer 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 7\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x8 , variables = forward_layer(x7)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-9. Run and Plot Layer 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 8\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x9, variables = forward_layer(x8)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-10. Run and Plot Layer 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 9\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x10, variables = forward_layer(x9)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-11. Run and Plot Layer 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 10\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x11, variables = forward_layer(x10)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-12. Run and Plot Layer 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 11\n",
    "thor_attention = thor_bert.attentions[layer_idx]\n",
    "thor_ff = thor_bert.ffs[layer_idx]\n",
    "x12, variables = forward_layer(x11)\n",
    "variables_list.append(variables)\n",
    "plot_variables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Pooler and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Run Pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thor_bert.pooler.to(devices)\n",
    "x = thor_bert.pooler.forward(x12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thor_bert.classifier.to(devices)\n",
    "x = thor_bert.classifier.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Comparison between the prediction and the actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the GLUE benchmark\n",
    "dataset = load_dataset(\"glue\", dataset_type)\n",
    "\n",
    "# Extract the validation split from the dataset\n",
    "val_set = dataset[\"validation\"]\n",
    "\n",
    "# Decrypt the encrypted predictions using the secret key\n",
    "a = engine.decrode(x[0], sk)[0]\n",
    "b = engine.decrode(x[1], sk)[0]\n",
    "\n",
    "# Predict 0 if a > b, otherwise predict 1\n",
    "pred = 0 if a > b else 1\n",
    "\n",
    "# Retrieve the ground-truth label from the validation set\n",
    "label = val_set[\"label\"][target_idx]\n",
    "\n",
    "# Display the prediction and the actual label\n",
    "print(f\"Predicted by HE: {pred}, Ground Truth: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "310THOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
